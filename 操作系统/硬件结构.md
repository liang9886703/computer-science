# CPU Cahce

CPU Cache，内存的速度访问越200-300个时钟周期，百倍于CPU，为了弥补两者的性能差异引入了CPU Cache高速缓存。包含L1 Cache、L2 Cache、L3 Cache。价格方面相差了466倍。

```shell
# 查看L1 Cache数据缓存的大小  32k
cat /sys/devices/system/cpu/cpu0/cache/index0/size
# 查看L1 Cache指令缓存的大小  32k
cat /sys/devices/system/cpu/cpu0/cache/index1/size
# 查看L2 Cache的大小         256k
cat /sys/devices/system/cpu/cpu0/cache/index2/size
# 查看L3 Cache的大小         3072k
cat /sys/devices/system/cpu/cpu0/cache/index3/size
# 查看L1 Cache数据缓存Cache Line一次载入数据的大小   64字节
cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size
```

L1分成数据缓存和指令缓存，通常他们大小一样，对于1+1=2，+是指令放在指令缓存，1是数据放在数据缓存

L3是所有CPU共享的，L1、L2是每个CPU都有的

![image-20231227090447386](image-20231227090447386.png)

CPU Cache由多个Cache Line组成，Cache Line又由Tag（头标志）+数据块（Data Block）组成

<img src="image-20231227091526030.png" alt="image-20231227091526030" style="zoom:25%;" />

CPU Cache的数据从内存读取过来，一小块一小块（即为缓存块Cache Line）读取数据，而不是按照单个数组元素来读取数据的

因此载入array[0]时，会一次载入64k的数据，即array[0]到array[15]的数据

**@ CPU如何判断数据是否在Cache里**

**直接映射策略**：把内存块的地址始终映射在一个CPU Cache Line的地址，映射关系的实现方式则是使用取模运算，取模运算的结果就是内存块地址对应的CPU Cache Line的地址

这就会导致有多个内存块会映射到同一个CPU Cache Line中，因此用**Tag（组标记）**来记录当前CPU Cache Line中存储的数据对应的内存块

Tag还有一个**有效位**，用来标记对应的CPU Cache Line中的数据是否有效，如果为0则访问内存重新加载数据

CPU读取数据时只读取CPU所需要的一个数据片段（CPU Cache Line中），即**字**，因此引入**偏移量**

因此，CPU通过组标记、CPU Cache Line索引、偏移量这三种信息找到数据

![image-20231227093644192](image-20231227093644192.png)

**当数据在CPU CacheCPU访问内存地址：**

1. 根据内存地址中的索引计算在CPU Cache的索引，
2. 判断有效位，如果无效就会直接访问内存并重新加载数据
3. 对比组标记，确认这个数据是我们要访问的数据，如果不是则直接访问内存并加载数据
4. 根据偏移量，从CPU Cache Line的数据块中读取对应的字

除了直接映射策略，还有全相连、组相连等

# 代码如何迎合cpu的执行

## 提高数据缓存的命中率

1. 对于二维数组，优先遍历列，再遍历行

```cpp
for(int i; i < N; i++){
    for(int j; j < N; j++){
        array[i][j];//速度更快
        array[j][i];//速度更慢
    }
}
```

## 提升指令缓存的命中率

```cpp
//操作一
for(int i = 0; i < N; i++){
    if(array[i]<50){
        array[i] = 0;
    }
}
//操作二
sort(array, array+N);
```

操作一和操作二的执行顺序会影响程序的性能，先执行操作二再执行操作一效率更高

CPU的分支预测，如果分支预测可以预测到接下来要执行if还是else，就可以提前把指令放进指令缓存中

当数组元素是顺序的，分支预测器会动态地根据历史命中数据对未来进行预测，先排序再遍历时，前几次遍历命中if<50的次数比较多，分支预测就会缓存if里的array[i]=0指令到Cache中，后续CPU执行该指令只需从Cache读取就好

当然显示的给出预测也可以，但一般CPU自身的预测已经足够了

```CPP
if(likely(a == 1)){
    ……
}else if(unlikely( a != 1)){
    ……
}
```

## 提升多核CPU的缓存命中率

现代CPU通过时间片可能在不同CPU核心来回切换执行，这对L1 L2 Cache是不利的，如果都在一个核心上执行，那么数据的L1和L2 Cache缓存命中率可以得到有效提高

当有多个计算密集型的线程，为了防止切换到不同的核心而导致缓存命中率下降，可以把线程绑定 在某个CPU核心上，即提高CPU亲和力

```cpp
#define _FNU_SOURCE
#include <sched.h>

int sched_setaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);
```

通常内核的基础都自带软亲和力，进程尽可能的执行在一个CPU上

有时也需要硬亲和力（强行将进程或线程绑定到某个指定的CPU核运行）

使用场景：

计算密集、提高Cache命中率、正在运行时间敏感的、决定性的进程